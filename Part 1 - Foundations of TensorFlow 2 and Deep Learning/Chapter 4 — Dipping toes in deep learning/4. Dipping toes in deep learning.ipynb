{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 4 — Dipping Toes in Deep Learning\n",
        "This chapter provides a practical introduction to three fundamental types of deep neural networks: Fully Connected Networks (FCNs), Convolutional Neural Networks (CNNs), and Recurrent Neural Networks (RNNs). Each section includes implementation examples and real-world applications."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Fully Connected Networks (FCNs)\n",
        "FCNs, also known as Multilayer Perceptrons (MLPs), form the foundation of deep learning. In this chapter, we explore autoencoders - a type of FCN used for unsupervised learning tasks like image reconstruction and denoising."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.1 Autoencoder Architecture\n",
        "Autoencoders learn to compress input data into a latent representation and then reconstruct it. They consist of:\n",
        "- **Encoder**: Compresses input to latent space\n",
        "- **Decoder**: Reconstructs input from latent space\n",
        "- **Applications**: Denoising, dimensionality reduction, pretraining\n",
        "\n",
        "**Key Concept**: The autoencoder takes corrupted images as input and learns to reconstruct the original images through compression and reconstruction phases."
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Implementation of Denoising Autoencoder\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "autoencoder = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(784, activation='tanh')\n",
        "])\n",
        "\n",
        "autoencoder.compile(loss='mse', optimizer='adam')\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.2 Training Process\n",
        "- **Input**: Corrupted images (50% pixels randomly set to 0)\n",
        "- **Target**: Original clean images\n",
        "- **Loss**: Mean Squared Error (MSE)\n",
        "- **Result**: Model learns to reconstruct original digits from corrupted versions\n",
        "- **Dataset**: MNIST - 70,000 handwritten digit images (28×28 pixels)"
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data preprocessing for MNIST\n",
        "import numpy as np\n",
        "\n",
        "def generate_masked_inputs(x, p, seed=None):\n",
        "    \"\"\"Generate corrupted images by randomly setting pixels to 0\"\"\"\n",
        "    if seed:\n",
        "        np.random.seed(seed)\n",
        "    mask = np.random.binomial(n=1, p=p, size=x.shape).astype('float32')\n",
        "    return x * mask\n",
        "\n",
        "# Normalize and reshape MNIST data\n",
        "norm_x_train = ((x_train - 128.0)/128.0).reshape([-1,784])\n",
        "masked_x_train = generate_masked_inputs(norm_x_train, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.3 Results and Applications\n",
        "- **Performance**: Loss decreases from ~0.15 to ~0.078 over 10 epochs\n",
        "- **Visual Results**: Model successfully reconstructs corrupted digit images\n",
        "- **Real-world Use**: Photo restoration, feature learning, pretraining for supervised tasks"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Convolutional Neural Networks (CNNs)\n",
        "CNNs revolutionized computer vision by preserving spatial information and learning hierarchical features through convolution and pooling operations."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.1 CNN Architecture Components\n",
        "- **Convolution Layers**: Extract spatial features using learnable filters\n",
        "- **Pooling Layers**: Reduce spatial dimensions (MaxPooling, AveragePooling)\n",
        "- **Fully Connected Layers**: Final classification layers\n",
        "- **Key Advantage**: Parameter efficiency through weight sharing"
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CNN Implementation for CIFAR-10\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    # First Conv-Pool Block\n",
        "    layers.Conv2D(16, (3,3), strides=(2,2), activation='relu', \n",
        "                  padding='same', input_shape=(32,32,3)),\n",
        "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "    \n",
        "    # Second Conv-Pool Block\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "    \n",
        "    # Fully Connected Layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.2 Convolution Operation Details\n",
        "Key hyperparameters that affect convolution output:\n",
        "\n",
        "**Filters**: Number of output channels  \n",
        "**Kernel Size**: Spatial dimensions of convolution window  \n",
        "**Strides**: Step size for sliding the kernel  \n",
        "**Padding**: 'same' (output size = input size) or 'valid' (no padding)\n",
        "\n",
        "**Output Size Formula**:  \n",
        "For valid padding: `output_size = (input_size - kernel_size) / stride + 1`  \n",
        "For same padding: `output_size = input_size / stride` (rounded up)"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.3 CIFAR-10 Implementation\n",
        "- **Dataset**: 50,000 training and 10,000 test images across 10 classes\n",
        "- **Image Size**: 32×32 RGB images\n",
        "- **Classes**: Airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "- **Results**: ~72% training accuracy after 25 epochs\n",
        "- **Application**: Vehicle detection feasibility study"
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data preparation for CIFAR-10\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "def format_data(x, depth):\n",
        "    \"\"\"Convert images to float32 and labels to one-hot\"\"\"\n",
        "    return (tf.cast(x[\"image\"], 'float32'), tf.one_hot(x[\"label\"], depth=depth))\n",
        "\n",
        "# Load and prepare dataset\n",
        "data = tfds.load('cifar10')\n",
        "tr_data = data[\"train\"].map(lambda x: format_data(x, depth=10)).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Recurrent Neural Networks (RNNs)\n",
        "RNNs are designed for sequential data and time series analysis, maintaining memory of previous inputs through hidden states."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3.1 RNN vs Feed-Forward Networks\n",
        "- **Feed-Forward**: Each input processed independently\n",
        "- **RNN**: Maintains hidden state that captures information from previous time steps\n",
        "- **Applications**: Time series forecasting, natural language processing, speech recognition\n",
        "- **Key Concept**: RNNs use previous context to inform current predictions"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3.2 CO2 Concentration Prediction\n",
        "Practical application: Predicting future CO2 levels using historical data\n",
        "- **Data Source**: Monthly CO2 concentration measurements since 1980\n",
        "- **Task**: Predict next month's CO2 level using previous 12 months\n",
        "- **Approach**: RNN learns temporal patterns in atmospheric CO2 data\n",
        "- **Columns**: Date, Decimal Date, Average CO2, Trend"
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data Preparation for CO2 Prediction\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def download_co2_data():\n",
        "    \"\"\"Download CO2 concentration data\"\"\"\n",
        "    save_dir = \"data\"\n",
        "    save_path = os.path.join(save_dir, 'co2-mm-gl.csv')\n",
        "    \n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    \n",
        "    if not os.path.exists(save_path):\n",
        "        url = \"https://datahub.io/core/co2-ppm/r/co2-mm-gl.csv\"\n",
        "        r = requests.get(url)\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "    \n",
        "    return save_path\n",
        "\n",
        "# Load and explore data\n",
        "data_path = download_co2_data()\n",
        "co2_data = pd.read_csv(data_path)\n",
        "print(\"CO2 Data Sample:\")\n",
        "print(co2_data.head())\n",
        "print(f\"\\nDataset shape: {co2_data.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3.3 Sequence Processing in RNNs\n",
        "RNNs process sequences by:\n",
        "- Maintaining internal state across time steps\n",
        "- Learning temporal dependencies\n",
        "- Using previous predictions to inform future ones\n",
        "- Handling variable-length sequences\n",
        "- **Mathematical Form**: h_t = f(W * x_t + U * h_{t-1} + b)"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Network Comparisons\n",
        "\n",
        "### Table 4.1 — Network Type Applications\n",
        "| Network Type | Best For | Key Features | Example Applications |\n",
        "|-------------|----------|--------------|---------------------|\n",
        "| FCNs | Tabular data, Simple patterns | Fully connected layers, No spatial preservation | Autoencoders, Basic classification |\n",
        "| CNNs | Image data, Spatial patterns | Convolution layers, Parameter sharing, Translation invariance | Image classification, Object detection |\n",
        "| RNNs | Sequential data, Time series | Hidden states, Temporal dependencies | Forecasting, NLP, Speech recognition |"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practical Considerations\n",
        "\n",
        "### 4.4.1 Hyperparameter Optimization\n",
        "- Deep learning models often use empirically chosen architectures\n",
        "- Hyperparameter optimization is computationally expensive\n",
        "- Common strategies: Transfer learning, following published architectures, rules of thumb\n",
        "- **Rule of Thumb**: Reduce output size as you go deeper into the network"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4.2 Performance Bottlenecks\n",
        "- **CNNs**: First fully connected layer after convolution blocks often contains most parameters\n",
        "- **Memory**: Large dense layers can cause out-of-memory errors\n",
        "- **Example**: 8×8×256 input to 1024-node dense layer = 16.7M parameters\n",
        "- **Solution**: Use global average pooling instead of flattening for large spatial dimensions"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4.3 Common Issues and Solutions\n",
        "- **Negative Dimension Error**: Caused by invalid convolution parameters\n",
        "- **Overfitting**: Use dropout, regularization, early stopping\n",
        "- **Training Stability**: Use batch normalization, gradient clipping\n",
        "- **Reproducibility**: Set random seeds for consistent results"
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix for negative dimension error in CNNs\n",
        "def calculate_output_size(input_size, kernel_size, stride, padding):\n",
        "    \"\"\"Calculate convolution output size to avoid errors\"\"\"\n",
        "    if padding == 'valid':\n",
        "        return (input_size - kernel_size) // stride + 1\n",
        "    else:  # 'same'\n",
        "        return (input_size + stride - 1) // stride\n",
        "\n",
        "# Example: Check if architecture is valid\n",
        "input_size = 32\n",
        "kernel_sizes = [(3,3), (3,3)]\n",
        "strides = [(2,2), (2,2)]\n",
        "\n",
        "current_size = input_size\n",
        "for i, (kernel, stride) in enumerate(zip(kernel_sizes, strides)):\n",
        "    current_size = calculate_output_size(current_size, kernel[0], stride[0], 'same')\n",
        "    print(f\"After layer {i+1}: {current_size}\")"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "### Exercise 1: Autoencoder Implementation\n",
        "Implement an autoencoder with architecture: 512 → 32 → 16 → 512 using sigmoid activation for all layers.\n",
        "\n",
        "### Exercise 2: CNN Output Size Calculation\n",
        "Calculate the final output size for the given CNN architecture (ignoring batch dimension):\n",
        "```python\n",
        "models.Sequential([\n",
        "    layers.Conv2D(16, (5,5), padding='valid', input_shape=(64,64,3)),\n",
        "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same'),\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "    layers.Conv2D(32, (3,3), strides=(2,2), activation='relu', padding='same')\n",
        "])\n",
        "```\n",
        "\n",
        "### Exercise 3: Data Pipeline Implementation\n",
        "Create a data pipeline for the CO2 dataset that prepares sequences of 12 months for RNN training."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 4 Summary\n",
        "\n",
        "This chapter provided hands-on experience with three fundamental deep learning architectures:\n",
        "\n",
        "1. **Fully Connected Networks (Autoencoders)**: \n",
        "   - Unsupervised learning for image reconstruction\n",
        "   - Compression and reconstruction phases\n",
        "   - Applications in denoising and feature learning\n        "   - MNIST dataset: 70,000 28×28 handwritten digit images\n\n        "2. **Convolutional Neural Networks**:\n        "   - Specialized for spatial data like images\n        "   - Hierarchical feature learning through convolution and pooling\n        "   - Parameter efficiency through weight sharing\n        "   - CIFAR-10 dataset: 60,000 32×32 color images across 10 classes\n        "   - Achieved ~72% training accuracy\n\n        "3. **Recurrent Neural Networks**:\n        "   - Designed for sequential and time-series data\n        "   - Maintain memory through hidden states\n        "   - Applications in forecasting and temporal pattern recognition\n        "   - CO2 concentration prediction using historical data\n\n        "**Key Takeaways**:\n        "- Each network type has distinct strengths for different data types\n        "- Proper parameter selection is crucial to avoid errors\n        "- Understanding these fundamentals enables exploration of advanced architectures\n        "- Real-world applications demonstrate practical utility of each approach"
      ]
    }
  ]
}
