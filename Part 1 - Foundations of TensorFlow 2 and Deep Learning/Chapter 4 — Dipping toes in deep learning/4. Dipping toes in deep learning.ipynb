{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 4 — Dipping Toes in Deep Learning\n",
        "This chapter provides a practical introduction to three fundamental types of deep neural networks: Fully Connected Networks (FCNs), Convolutional Neural Networks (CNNs), and Recurrent Neural Networks (RNNs). Each section includes implementation examples and real-world applications."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Fully Connected Networks (FCNs)\n",
        "FCNs, also known as Multilayer Perceptrons (MLPs), form the foundation of deep learning. In this chapter, we explore autoencoders - a type of FCN used for unsupervised learning tasks like image reconstruction and denoising."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.1 — MNIST Dataset Samples\n",
        "<p align='left'><img src='./figure/figure4.1.png' width='60%'></p>\n",
        "The MNIST dataset contains 70,000 handwritten digit images (60,000 training, 10,000 test). Each image is 28×28 pixels with labels 0-9."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.1 Autoencoder Architecture\n",
        "Autoencoders learn to compress input data into a latent representation and then reconstruct it. They consist of:\n",
        "- **Encoder**: Compresses input to latent space\n",
        "- **Decoder**: Reconstructs input from latent space\n",
        "- **Applications**: Denoising, dimensionality reduction, pretraining"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.2 — Autoencoder Structure\n",
        "<p align='left'><img src='./figure/figure4.2.png' width='60%'></p>\n",
        "The autoencoder takes corrupted images as input and learns to reconstruct the original images through compression and reconstruction phases."
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Implementation of Denoising Autoencoder\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "autoencoder = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(784, activation='tanh')\n",
        "])\n",
        "\n",
        "autoencoder.compile(loss='mse', optimizer='adam')\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.2 Training Process\n",
        "- **Input**: Corrupted images (50% pixels randomly set to 0)\n",
        "- **Target**: Original clean images\n",
        "- **Loss**: Mean Squared Error (MSE)\n",
        "- **Result**: Model learns to reconstruct original digits from corrupted versions"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.3 — Image Reconstruction Results\n",
        "<p align='left'><img src='./figure/figure4.3.png' width='60%'></p>\n",
        "Comparison between corrupted input images (top row) and reconstructed outputs (bottom row) showing the autoencoder's denoising capability."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Convolutional Neural Networks (CNNs)\n",
        "CNNs revolutionized computer vision by preserving spatial information and learning hierarchical features through convolution and pooling operations."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.1 CNN Architecture Components\n",
        "- **Convolution Layers**: Extract spatial features using learnable filters\n",
        "- **Pooling Layers**: Reduce spatial dimensions (MaxPooling, AveragePooling)\n",
        "- **Fully Connected Layers**: Final classification layers"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.4 — CNN Architecture Overview\n",
        "<p align='left'><img src='./figure/figure4.4.png' width='60%'></p>\n",
        "Typical CNN structure showing convolution-pooling blocks followed by fully connected layers for classification."
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CNN Implementation for CIFAR-10\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    # First Conv-Pool Block\n",
        "    layers.Conv2D(16, (3,3), strides=(2,2), activation='relu', \n",
        "                  padding='same', input_shape=(32,32,3)),\n",
        "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "    \n",
        "    # Second Conv-Pool Block\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "    \n",
        "    # Fully Connected Layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.2 Convolution Operation Details\n",
        "Key hyperparameters that affect convolution output:\n",
        "- **Filters**: Number of output channels\n",
        "- **Kernel Size**: Spatial dimensions of convolution window\n",
        "- **Strides**: Step size for sliding the kernel\n",
        "- **Padding**: 'same' (output size = input size) or 'valid' (no padding)"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.5 — Convolution Operation Visualization\n",
        "<p align='left'><img src='./figure/figure4.5.png' width='60%'></p>\n",
        "Illustration of how convolution kernels slide over input images to produce feature maps."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.6 — Feature Hierarchy in CNNs\n",
        "<p align='left'><img src='./figure/figure4.6.png' width='60%'></p>\n",
        "Deep CNN layers learn hierarchical features: early layers detect edges, middle layers detect patterns, and deeper layers detect complex objects."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.3 CIFAR-10 Implementation\n",
        "- **Dataset**: 50,000 training and 10,000 test images across 10 classes\n",
        "- **Image Size**: 32×32 RGB images\n",
        "- **Classes**: Airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "- **Results**: ~72% training accuracy after 25 epochs"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Recurrent Neural Networks (RNNs)\n",
        "RNNs are designed for sequential data and time series analysis, maintaining memory of previous inputs through hidden states."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3.1 RNN vs Feed-Forward Networks\n",
        "- **Feed-Forward**: Each input processed independently\n",
        "- **RNN**: Maintains hidden state that captures information from previous time steps\n",
        "- **Applications**: Time series forecasting, natural language processing, speech recognition"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.7 — RNN Architecture\n",
        "<p align='left'><img src='./figure/figure4.7.png' width='60%'></p>\n",
        "RNN processing sequence data where each time step receives current input and previous hidden state to produce output and updated hidden state."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3.2 CO2 Concentration Prediction\n",
        "Practical application: Predicting future CO2 levels using historical data\n",
        "- **Data Source**: Monthly CO2 concentration measurements since 1980\n",
        "- **Task**: Predict next month's CO2 level using previous 12 months\n",
        "- **Approach**: RNN learns temporal patterns in atmospheric CO2 data"
      ]
    },

    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data Preparation for CO2 Prediction\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def download_co2_data():\n",
        "    \"\"\"Download CO2 concentration data\"\"\"\n",
        "    save_dir = \"data\"\n",
        "    save_path = os.path.join(save_dir, 'co2-mm-gl.csv')\n",
        "    \n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    \n",
        "    if not os.path.exists(save_path):\n",
        "        url = \"https://datahub.io/core/co2-ppm/r/co2-mm-gl.csv\"\n",
        "        r = requests.get(url)\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "    \n",
        "    return save_path\n",
        "\n",
        "# Load and explore data\n",
        "data_path = download_co2_data()\n",
        "co2_data = pd.read_csv(data_path)\n",
        "print(co2_data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 4.8 — CO2 Data Sample\n",
        "<p align='left'><img src='./figure/figure4.8.png' width='60%'></p>\n",
        "Sample of CO2 dataset showing date, decimal date, average concentration, and trend columns."
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3.3 Sequence Processing\n",
        "RNNs process sequences by:\n",
        "- Maintaining internal state across time steps\n",
        "- Learning temporal dependencies\n",
        "- Using previous predictions to inform future ones\n",
        "- Handling variable-length sequences"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Network Comparisons\n",
        "\n",
        "### Table 4.1 — Network Type Applications\n",
        "| Network Type | Best For | Key Features | Example Applications |\n",
        "|-------------|----------|--------------|---------------------|\n",
        "| FCNs | Tabular data, Simple patterns | Fully connected layers, No spatial preservation | Autoencoders, Basic classification |\n",
        "| CNNs | Image data, Spatial patterns | Convolution layers, Parameter sharing, Translation invariance | Image classification, Object detection |\n",
        "| RNNs | Sequential data, Time series | Hidden states, Temporal dependencies | Forecasting, NLP, Speech recognition |"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practical Considerations\n",
        "\n",
        "### 4.4.1 Hyperparameter Optimization\n",
        "- Deep learning models often use empirically chosen architectures\n",
        "- Hyperparameter optimization is computationally expensive\n",
        "- Common strategies: Transfer learning, following published architectures, rules of thumb\n",
        "\n",
        "### 4.4.2 Performance Bottlenecks\n",
        "- **CNNs**: First fully connected layer after convolution blocks often contains most parameters\n",
        "- **Memory**: Large dense layers can cause out-of-memory errors\n",
        "- **Solution**: Use global average pooling instead of flattening for large spatial dimensions"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "### Exercise 1: Autoencoder Implementation\n",
        "Implement an autoencoder with architecture: 512 → 32 → 16 → 512 using sigmoid activation for all layers.\n",
        "\n",
        "### Exercise 2: CNN Output Size Calculation\n",
        "Calculate the final output size for the given CNN architecture (ignoring batch dimension):\n",
        "```python\n",
        "models.Sequential([\n",
        "    layers.Conv2D(16, (5,5), padding='valid', input_shape=(64,64,3)),\n",
        "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same'),\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "    layers.Conv2D(32, (3,3), strides=(2,2), activation='relu', padding='same')\n",
        "])\n",
        "```"
      ]
    },

    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 4 Summary\n",
        "\n",
        "This chapter provided hands-on experience with three fundamental deep learning architectures:\n",
        "\n",
        "1. **Fully Connected Networks (Autoencoders)**: \n",
        "   - Unsupervised learning for image reconstruction\n",
        "   - Compression and reconstruction phases\n",
        "   - Applications in denoising and feature learning\n",
        "\n",
        "2. **Convolutional Neural Networks**:\n",
        "   - Specialized for spatial data like images\n",
        "   - Hierarchical feature learning through convolution and pooling\n",
        "   - Parameter efficiency through weight sharing\n",
        "\n",
        "3. **Recurrent Neural Networks**:\n",
        "   - Designed for sequential and time-series data\n",
        "   - Maintain memory through hidden states\n",
        "   - Applications in forecasting and temporal pattern recognition\n",
        "\n",
        "Each network type has distinct strengths and is suited for different types of data and tasks. Understanding these fundamental architectures provides the foundation for exploring more advanced deep learning models and applications."
      ]
    }
  ]
}
